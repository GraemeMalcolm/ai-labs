[
  {
    "id": 1,
    "category": "Generative AI",
    "file": "01-language-models.md",
    "heading": "Tokenization",
    "content": "The first step is to provide the model with a large vocabulary of words and phrases; and we do mean *large*. The latest generation of LLMs have vocabularies that consist of hundreds of thousands of tokens, based on large volumes of training data from across the Internet and other sources.\n\nWait a minute. *Tokens*?\n\nWhile we tend to think of language in terms of *words*, LLMs break down their vocabulary into *tokens*. Tokens include words, but also *sub*-words (like the \"un\" in \"unbelievable\" and",
    "summary": "The first step is to provide the model with a large vocabulary of words and phrases; and we do mean *large*. The latest generation of LLMs have vocabularies that consist of hundreds of thousands of to...",
    "keywords": [
      "unique",
      "tokens",
      "wait",
      "model",
      "others",
      "step",
      "data",
      "while",
      "latest",
      "based",
      "language",
      "commonly",
      "more",
      "sequences",
      "assign",
      "identifier",
      "already",
      "phrases",
      "sources",
      "terms"
    ]
  },
  {
    "id": 2,
    "category": "Generative AI",
    "file": "01-language-models.md",
    "heading": "Transforming tokens with a *transformer*",
    "content": "Now that we have a set of tokens with unique IDs, we need to find a way to relate them to one another. To do this, we assign each token a *vector* (an array of multiple numeric values, like [1, 23, 45]). Each vector has multiple numeric *elements* or *dimensions*, and we can use these to encode linguistic and semantic attributes of the token to help provide a great deal of information about what the token *means* and how it relates to other tokens, in an efficient format.\n\nWe need to transform t",
    "summary": "Now that we have a set of tokens with unique IDs, we need to find a way to relate them to one another. To do this, we assign each token a *vector* (an array of multiple numeric values, like [1, 23, 45...",
    "keywords": [
      "unique",
      "fully",
      "characteristics",
      "diagram",
      "process",
      "embeddings",
      "connected",
      "numeric",
      "multi-head",
      "calculate",
      "values",
      "help",
      "consists",
      "weights",
      "need",
      "efficient",
      "initial",
      "representations",
      "attention",
      "which"
    ]
  },
  {
    "id": 3,
    "category": "Generative AI",
    "file": "01-language-models.md",
    "heading": "Initial vectors and positional encoding",
    "content": "Initially, the token vector values are assigned randomly, before being fed through the transformer to create embedding vectors. The token vectors are fed into the transformer along with a *positional encoding* that indicates where the token appears in the sequence of training text (we need to do this because the order in which tokens appear in the sequence is relevant to how they relate to one another). For example, our tokens might start off looking like this:\n\n|Token | Token ID | Position | Ve",
    "summary": "Initially, the token vector values are assigned randomly, before being fed through the transformer to create embedding vectors. The token vectors are fed into the transformer along with a *positional...",
    "keywords": [
      "they",
      "tokens",
      "indicates",
      "vector",
      "start",
      "position",
      "like",
      "values",
      "example",
      "heard",
      "order",
      "because",
      "initially",
      "vectors",
      "need",
      "loudly",
      "relevant",
      "initial",
      "assigned",
      "encoding"
    ]
  },
  {
    "id": 4,
    "category": "Generative AI",
    "file": "01-language-models.md",
    "heading": "Attention and embeddings",
    "content": "To determine the vector representations of tokens that include embedded contextual information, the transformer uses *attention* layers. An attention layer considers each token in turn, within the context of the sequence of tokens in which it appears. The tokens around the current one are weighted to reflect their influence and the weights are used to calculate the element values for the current token's embedding vector. For example, when considering the token \"bark\" in the context of \"I heard a",
    "summary": "To determine the vector representations of tokens that include embedded contextual information, the transformer uses *attention* layers. An attention layer considers each token in turn, within the con...",
    "keywords": [
      "semantically",
      "others",
      "embed-example",
      "characteristics",
      "stick",
      "diagram",
      "same",
      "process",
      "point",
      "using",
      "embeddings",
      "visualize",
      "multi-head",
      "calculate",
      "values",
      "help",
      "look",
      "three-dimensional",
      "initially",
      "weights"
    ]
  },
  {
    "id": 5,
    "category": "Generative AI",
    "file": "01-language-models.md",
    "heading": "Predicting completions from prompts",
    "content": "Now that we have a set of embeddings that encapsulate the contextual relationship between tokens, we can use the *decoder* block of a transformer to iteratively predict the next word in a sequence based on a starting *prompt*.\n\nOnce again, *attention* is used to consider each token in context; but this time the context to be considered can only include the tokens that *precede* the token we're trying to predict. The decoder model is trained, using data for which we already have the full sequence",
    "summary": "Now that we have a set of embeddings that encapsulate the contextual relationship between tokens, we can use the *decoder* block of a transformer to iteratively predict the next word in a sequence bas...",
    "keywords": [
      "prompts",
      "process",
      "using",
      "embeddings",
      "unknown",
      "calculate",
      "candidate",
      "help",
      "again",
      "error",
      "weights",
      "attention",
      "current",
      "which",
      "completions",
      "feed-forward",
      "prompt",
      "during",
      "reduce",
      "know"
    ]
  },
  {
    "id": 6,
    "category": "Generative AI",
    "file": "02-writing-prompts.md",
    "heading": "Types of prompt",
    "content": "There are two main types of prompts:\n\n- **System prompts** that set the behavior and tone of the model, and any constraints it should adhere to. For example, \"*You're a helpful assistant that responds in a cheerful, friendly manner.*\". System prompts determine constraints and styles for the model's responses.\n- **User prompts** that elicit a response to a specific question or instruction. For example, \"*Summarize the key considerations for adopting generative AI described in <u>GenAI_Considerati",
    "summary": "There are two main types of prompts:\n\n- **System prompts** that set the behavior and tone of the model, and any constraints it should adhere to. For example, \"*You're a helpful assistant that responds...",
    "keywords": [
      "prompts",
      "genai",
      "model",
      "main",
      "behalf",
      "elicit",
      "system-prompt",
      "responses",
      "guidance",
      "while",
      "constraints",
      "responds",
      "summary",
      "diagram",
      "tone",
      "chat",
      "more",
      "media",
      "bullet",
      "adhere"
    ]
  },
  {
    "id": 7,
    "category": "Generative AI",
    "file": "02-writing-prompts.md",
    "heading": "Conversation history",
    "content": "To keep a conversation consistent and relevant, generative AI apps often keep track of the conversation history; and include summarized versions of it in subsequent prompts. This ensures there’s an ongoing context for the conversation that the model can build on.\n\n![Diagram of a conversation with multiple prompts and completions.](../media/conversation-history.png)\n\nFor example, suppose the model responds to the system and user prompts described previously with the following completion:\n\n> *Key ",
    "summary": "To keep a conversation consistent and relevant, generative AI apps often keep track of the conversation history; and include summarized versions of it in subsequent prompts. This ensures there’s an on...",
    "keywords": [
      "prompts",
      "risks",
      "diagram",
      "common",
      "corporate",
      "apps",
      "security",
      "user",
      "measure",
      "ahead",
      "ongoing",
      "relation",
      "completions",
      "across",
      "prompt",
      "conversation",
      "context",
      "history",
      "respond",
      "media"
    ]
  },
  {
    "id": 8,
    "category": "Generative AI",
    "file": "02-writing-prompts.md",
    "heading": "Retrieval augmented generation (RAG)",
    "content": "To add even more context, generative AI applications can use a technique called *retrieval augmented generation (RAG)*. This approach involves retrieving information, like documents or emails, and using it to augment the prompt with relevant data. The response generated by the model is then *grounded* in the information that was provided.\n\nFor example, suppose you submit a prompt like \"*What's the maximum I can claim for travel expenses on a business trip?*\". With no other information, a model w",
    "summary": "To add even more context, generative AI applications can use a technique called *retrieval augmented generation (RAG)*. This approach involves retrieving information, like documents or emails, and usi...",
    "keywords": [
      "even",
      "organization",
      "model",
      "retrieving",
      "probably",
      "technique",
      "data",
      "documentation",
      "diagram",
      "augmented",
      "more",
      "solution",
      "original",
      "media",
      "retrieval-augmented-generation",
      "emails",
      "using",
      "related",
      "includes",
      "approach"
    ]
  },
  {
    "id": 9,
    "category": "Generative AI",
    "file": "02-writing-prompts.md",
    "heading": "Tips for better prompts",
    "content": "The quality of responses from generative AI assistants not only depends on the language model used, but on the prompts you submit to it.\n\n![Diagram of a clear and specific prompt with context, examples, and a request for structure.](../media/writing-prompts.png)\n\nTo get better results from your prompts:\n\n- Be **clear** and **specific** – prompts with explicit instructions or questions work better than vague language.\n- Add **context** - mention the topic, audience, or format you want.\n- Use **ex",
    "summary": "The quality of responses from generative AI assistants not only depends on the language model used, but on the prompts you submit to it.\n\n![Diagram of a clear and specific prompt with context, example...",
    "keywords": [
      "prompts",
      "assistants",
      "examples",
      "results",
      "model",
      "request",
      "vague",
      "depends",
      "responses",
      "mention",
      "audience",
      "diagram",
      "language",
      "structure",
      "bullet",
      "using",
      "work",
      "format",
      "example",
      "like"
    ]
  },
  {
    "id": 10,
    "category": "Generative AI",
    "file": "03-agents.md",
    "heading": "Components of an AI agent",
    "content": "![Diagram of an agent with a model, instructions, and tools.](../media/agent.png)\n\nAI agents have three key elements:\n\n- **A large language model**: This is the agent's brain; using generative AI for language understanding and reasoning.\n- **Instructions**: A system prompt that defines the agent’s role and behavior. Think of it as the agent’s job description.\n- **Tools**: These are what the agent uses to interact with the world. Tools can include:\n    - *Knowledge* tools that provide access to i",
    "summary": "![Diagram of an agent with a model, instructions, and tools.](../media/agent.png)\n\nAI agents have three key elements:\n\n- **A large language model**: This is the agent's brain; using generative AI for...",
    "keywords": [
      "world",
      "databases",
      "assistants",
      "knowledge",
      "three",
      "model",
      "collaborate",
      "interact",
      "take",
      "efficiently",
      "diagram",
      "language",
      "more",
      "updating",
      "agents",
      "calendars",
      "emails",
      "using",
      "devices",
      "enable"
    ]
  },
  {
    "id": 11,
    "category": "Generative AI",
    "file": "03-agents.md",
    "heading": "Multi-agent systems",
    "content": "Agents can also work with one another, in multi-agent systems. Instead of one agent doing everything, multiple agents can collaborate—each with its own specialty. One might gather data, another might analyze it, and a third might take action. Together, they form an AI-powered workforce that can handle complex workflows, just like a human team.\n\n![Diagram of a multi-agent system.](../media/multiple-agents.png)\n\nAgents communicate with each other through prompts, using generative AI to determine w",
    "summary": "Agents can also work with one another, in multi-agent systems. Instead of one agent doing everything, multiple agents can collaborate—each with its own specialty. One might gather data, another might...",
    "keywords": [
      "prompts",
      "systems",
      "they",
      "team",
      "collaborate",
      "instead",
      "completing",
      "gather",
      "take",
      "just",
      "advance",
      "find",
      "ai-powered",
      "data",
      "complex",
      "diagram",
      "agents",
      "them",
      "human",
      "using"
    ]
  }
]