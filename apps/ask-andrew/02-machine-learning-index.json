[
  {
    "id": 12,
    "category": "Machine Learning",
    "file": "02-types-of-machine-learning.md",
    "heading": "Supervised machine learning",
    "content": "*Supervised* machine learning is a general term for machine learning algorithms in which the training data includes both *feature* values and known *label* values. Supervised machine learning is used to train models by determining a relationship between the features and labels in past observations, so that unknown labels can be predicted for features in future cases.",
    "summary": "*Supervised* machine learning is a general term for machine learning algorithms in which the training data includes both *feature* values and known *label* values. Supervised machine learning is used...",
    "keywords": [
      "general",
      "past",
      "features",
      "models",
      "data",
      "term",
      "algorithms",
      "observations",
      "unknown",
      "includes",
      "values",
      "between",
      "feature",
      "both",
      "machine",
      "future",
      "which",
      "predicted",
      "supervised",
      "used"
    ]
  },
  {
    "id": 13,
    "category": "Machine Learning",
    "file": "02-types-of-machine-learning.md",
    "heading": "Regression",
    "content": "*Regression* is a form of supervised machine learning in which the label predicted by the model is a numeric value. For example:\n\n- The number of ice creams sold on a given day, based on the temperature, rainfall, and windspeed.\n- The selling price of a property based on its size in square feet, the number of bedrooms it contains, and socio-economic metrics for its location.\n- The fuel efficiency (in miles-per-gallon) of a car based on its engine size, weight, width, height, and length.",
    "summary": "*Regression* is a form of supervised machine learning in which the label predicted by the model is a numeric value. For example:\n\n- The number of ice creams sold on a given day, based on the temperatu...",
    "keywords": [
      "weight",
      "sold",
      "model",
      "selling",
      "location",
      "rainfall",
      "regression",
      "based",
      "given",
      "efficiency",
      "feet",
      "numeric",
      "creams",
      "example",
      "size",
      "bedrooms",
      "form",
      "square",
      "metrics",
      "miles-per-gallon"
    ]
  },
  {
    "id": 14,
    "category": "Machine Learning",
    "file": "02-types-of-machine-learning.md",
    "heading": "Classification",
    "content": "*Classification* is a form of supervised machine learning in which the label represents a categorization, or *class*. There are two common classification scenarios.",
    "summary": "*Classification* is a form of supervised machine learning in which the label represents a categorization, or *class*. There are two common classification scenarios.",
    "keywords": [
      "learning",
      "machine",
      "which",
      "label",
      "class",
      "there",
      "common",
      "classification",
      "form",
      "represents",
      "supervised",
      "categorization",
      "scenarios"
    ]
  },
  {
    "id": 15,
    "category": "Machine Learning",
    "file": "02-types-of-machine-learning.md",
    "heading": "Binary classification",
    "content": "In *binary classification*, the label determines whether the observed item *is* (or *isn't*) an instance of a specific class. Or put another way, binary classification models predict one of two mutually exclusive outcomes. For example:\n\n- Whether a patient is at risk for diabetes based on clinical metrics like weight, age, blood glucose level, and so on.\n- Whether a bank customer will default on a loan based on income, credit history, age, and other factors.\n- Whether a mailing list customer wil",
    "summary": "In *binary classification*, the label determines whether the observed item *is* (or *isn't*) an instance of a specific class. Or put another way, binary classification models predict one of two mutual...",
    "keywords": [
      "income",
      "examples",
      "weight",
      "blood",
      "mailing",
      "risk",
      "past",
      "model",
      "models",
      "single",
      "item",
      "based",
      "marketing",
      "mutually",
      "true",
      "outcomes",
      "predict",
      "binary",
      "example",
      "instance"
    ]
  },
  {
    "id": 16,
    "category": "Machine Learning",
    "file": "02-types-of-machine-learning.md",
    "heading": "Multiclass classification",
    "content": "*Multiclass classification* extends binary classification to predict a label that represents one of multiple possible classes. For example,\n\n- The species of a penguin (*Adelie*, *Gentoo*, or *Chinstrap*) based on its physical measurements.\n- The genre of a movie (*comedy*, *horror*, *romance*, *adventure*, or *science fiction*) based on its cast, director, and budget.\n\nIn most scenarios that involve a known set of multiple classes, multiclass classification is used to predict mutually exclusive",
    "summary": "*Multiclass classification* extends binary classification to predict a label that represents one of multiple possible classes. For example,\n\n- The species of a penguin (*Adelie*, *Gentoo*, or *Chinstr...",
    "keywords": [
      "classes",
      "adelie",
      "categorized",
      "director",
      "physical",
      "romance",
      "models",
      "genre",
      "based",
      "budget",
      "mutually",
      "multilabel",
      "more",
      "algorithms",
      "movie",
      "involve",
      "predict",
      "binary",
      "example",
      "potentially"
    ]
  },
  {
    "id": 17,
    "category": "Machine Learning",
    "file": "02-types-of-machine-learning.md",
    "heading": "Unsupervised machine learning",
    "content": "*Unsupervised* machine learning involves training models using data that consists only of *feature* values without any known labels. Unsupervised machine learning algorithms determine relationships between the features of the observations in the training data.",
    "summary": "*Unsupervised* machine learning involves training models using data that consists only of *feature* values without any known labels. Unsupervised machine learning algorithms determine relationships be...",
    "keywords": [
      "features",
      "models",
      "data",
      "algorithms",
      "using",
      "without",
      "values",
      "between",
      "feature",
      "consists",
      "relationships",
      "involves",
      "machine",
      "only",
      "learning",
      "unsupervised",
      "determine",
      "labels",
      "known",
      "training"
    ]
  },
  {
    "id": 18,
    "category": "Machine Learning",
    "file": "02-types-of-machine-learning.md",
    "heading": "Clustering",
    "content": "The most common form of unsupervised machine learning is *clustering*. A clustering algorithm identifies similarities between observations based on their features, and groups them into discrete clusters. For example:\n\n- Group similar flowers based on their size, number of leaves, and number of petals.\n- Identify groups of similar customers based on demographic attributes and purchasing behavior.\n\nIn some ways, clustering is similar to multiclass classification; in that it categorizes observation",
    "summary": "The most common form of unsupervised machine learning is *clustering*. A clustering algorithm identifies similarities between observations based on their features, and groups them into discrete cluste...",
    "keywords": [
      "using",
      "ways",
      "common",
      "customer",
      "groups",
      "algorithm",
      "similar",
      "which",
      "identify",
      "number",
      "some",
      "belong",
      "categorizations",
      "know",
      "categorize",
      "used",
      "unsupervised",
      "their",
      "determining",
      "when"
    ]
  },
  {
    "id": 19,
    "category": "Machine Learning",
    "file": "03-regression.md",
    "heading": "Example - regression",
    "content": "Let's explore regression with a simplified example in which we'll train a model to predict a numeric label (***y***) based on a single feature value (***x***). Most real scenarios involve multiple feature values, which adds some complexity; but the principle is the same.\n\nFor our example, let's stick with the ice cream sales scenario we discussed previously. For our feature, we'll consider the *temperature* (let's assume the value is the maximum temperature on a given day), and the label we want",
    "summary": "Let's explore regression with a simplified example in which we'll train a model to predict a numeric label (***y***) based on a single feature value (***x***). Most real scenarios involve multiple fea...",
    "keywords": [
      "sold",
      "real",
      "model",
      "sales",
      "records",
      "simplified",
      "regression",
      "stick",
      "data",
      "ice-creams",
      "based",
      "diagram",
      "temperatures",
      "same",
      "given",
      "media",
      "previously",
      "start",
      "adds",
      "involve"
    ]
  },
  {
    "id": 20,
    "category": "Machine Learning",
    "file": "03-regression.md",
    "heading": "Training a regression model",
    "content": "We'll start by splitting the data and using a subset of it to train a model. Here's the training dataset:\n\n|Temperature (x) | Ice cream sales (y)|\n|---|---|\n|51|1|\n|65|14|\n|69|20|\n|72|23|\n|75|26|\n|81|30|\n\nTo get an insight of how these ***x*** and ***y*** values might relate to one another, we can plot them as coordinates along two axes, like this:\n\n![Diagram of a scatter plot showing x and y.](../media/scatter-plot.png)\n\nNow we're ready to apply an algorithm to our training data and fit it to a",
    "summary": "We'll start by splitting the data and using a subset of it to train a model. Here's the training dataset:\n\n|Temperature (x) | Ice cream sales (y)|\n|---|---|\n|51|1|\n|65|14|\n|69|20|\n|72|23|\n|75|26|\n|81|...",
    "keywords": [
      "showing",
      "diagram",
      "weather",
      "using",
      "calculate",
      "plotted",
      "values",
      "operation",
      "algorithm",
      "which",
      "slopes",
      "apply",
      "describes",
      "number",
      "plot",
      "another",
      "subset",
      "linear",
      "through",
      "expressed"
    ]
  },
  {
    "id": 21,
    "category": "Machine Learning",
    "file": "03-regression.md",
    "heading": "Evaluating a regression model",
    "content": "To validate the model and evaluate how well it predicts, we held back some data for which we know the label (***y***) value. Here's the data we held back:\n\n|Temperature (x) | Ice cream sales (y)|\n|---|---|\n|52|0|\n|67|14|\n|70|23|\n|73|22|\n|78|26|\n|83|36|\n\nWe can use the model to predict the label for each of the observations in this dataset based on the feature (***x***) value; and then compare the predicted label (***&#375;***) to the known actual label value (***y***).\n\nUsing the model we traine",
    "summary": "To validate the model and evaluate how well it predicts, we held back some data for which we know the label (***y***) value. Here's the data we held back:\n\n|Temperature (x) | Ice cream sales (y)|\n|---...",
    "keywords": [
      "function",
      "results",
      "they",
      "validate",
      "encapsulates",
      "model",
      "sales",
      "showing",
      "regression-variance",
      "regression",
      "data",
      "validation",
      "based",
      "diagram",
      "indicated",
      "evaluating",
      "dataset",
      "well",
      "using",
      "predict"
    ]
  },
  {
    "id": 22,
    "category": "Machine Learning",
    "file": "03-regression.md",
    "heading": "Regression evaluation metrics",
    "content": "Based on the differences between the predicted and actual values, you can calculate some common metrics that are used to evaluate a regression model.",
    "summary": "Based on the differences between the predicted and actual values, you can calculate some common metrics that are used to evaluate a regression model.",
    "keywords": [
      "metrics",
      "used",
      "model",
      "calculate",
      "common",
      "predicted",
      "evaluation",
      "between",
      "values",
      "evaluate",
      "some",
      "regression",
      "based",
      "actual",
      "differences"
    ]
  },
  {
    "id": 23,
    "category": "Machine Learning",
    "file": "03-regression.md",
    "heading": "Mean Absolute Error (MAE)",
    "content": "The variance in this example indicates by how many ice creams each prediction was wrong. It doesn't matter if the prediction was *over* or *under* the actual value (so for example, -3 and +3 both indicate a variance of 3). This metric is known as the *absolute error* for each prediction, and can be summarized for the whole validation set as the **mean absolute error** (MAE).\n\nIn the ice cream example, the mean (average) of the absolute errors (2, 3, 3, 1, 2, and 3) is **2.33**.",
    "summary": "The variance in this example indicates by how many ice creams each prediction was wrong. It doesn't matter if the prediction was *over* or *under* the actual value (so for example, -3 and +3 both indi...",
    "keywords": [
      "doesn",
      "average",
      "over",
      "summarized",
      "absolute",
      "validation",
      "indicates",
      "wrong",
      "whole",
      "creams",
      "example",
      "indicate",
      "error",
      "actual",
      "both",
      "metric",
      "each",
      "under",
      "errors",
      "many"
    ]
  },
  {
    "id": 24,
    "category": "Machine Learning",
    "file": "03-regression.md",
    "heading": "Mean Squared Error (MSE)",
    "content": "The mean absolute error metric takes all discrepancies between predicted and actual labels into account equally. However, it may be more desirable to have a model that is consistently wrong by a small amount than one that makes fewer, but larger errors. One way to produce a metric that \"amplifies\" larger errors by *squaring* the individual errors and calculating the mean of the squared values. This metric is known as the **mean squared error** (MSE).\n\nIn our ice cream example, the mean of the sq",
    "summary": "The mean absolute error metric takes all discrepancies between predicted and actual labels into account equally. However, it may be more desirable to have a model that is consistently wrong by a small...",
    "keywords": [
      "model",
      "larger",
      "absolute",
      "equally",
      "more",
      "wrong",
      "produce",
      "values",
      "example",
      "between",
      "error",
      "amount",
      "actual",
      "squaring",
      "metric",
      "consistently",
      "however",
      "which",
      "makes",
      "predicted"
    ]
  },
  {
    "id": 25,
    "category": "Machine Learning",
    "file": "03-regression.md",
    "heading": "Root Mean Squared Error (RMSE)",
    "content": "The mean squared error helps take the magnitude of errors into account, but because it *squares* the error values, the resulting metric no longer represents the quantity measured by the label. In other words, we can say that the MSE of our model is 6, but that doesn't measure its accuracy in terms of the number of ice creams that were mispredicted; 6 is just a numeric score that indicates the level of error in the validation predictions.\n\nIf we want to measure the error in terms of the number of",
    "summary": "The mean squared error helps take the magnitude of errors into account, but because it *squares* the error values, the resulting metric no longer represents the quantity measured by the label. In othe...",
    "keywords": [
      "score",
      "8730",
      "case",
      "model",
      "doesn",
      "longer",
      "take",
      "just",
      "root",
      "validation",
      "unsurprisingly",
      "indicates",
      "squares",
      "helps",
      "rmse",
      "mispredicted",
      "accuracy",
      "produces",
      "resulting",
      "quantity"
    ]
  },
  {
    "id": 26,
    "category": "Machine Learning",
    "file": "03-regression.md",
    "heading": "Coefficient of determination (R<sup>2</sup>)",
    "content": "All of the metrics so far compare the discrepancy between the predicted and actual values in order to evaluate the model. However, in reality, there's some natural random variance in the daily sales of ice cream that the model takes into account. In a linear regression model, the training algorithm fits a straight line that minimizes the mean variance between the function and the known label values. The **coefficient of determination** (more commonly referred to as **R<sup>2</sup>** or **R-Squar",
    "summary": "All of the metrics so far compare the discrepancy between the predicted and actual values in order to evaluate the model. However, in reality, there's some natural random variance in the daily sales o...",
    "keywords": [
      "complex",
      "local",
      "minimizes",
      "point",
      "terms",
      "calculate",
      "values",
      "algorithm",
      "metrics",
      "however",
      "describes",
      "number",
      "some",
      "discrepancy",
      "mean",
      "linear",
      "important",
      "variance",
      "function",
      "opposed"
    ]
  },
  {
    "id": 27,
    "category": "Machine Learning",
    "file": "03-regression.md",
    "heading": "Iterative training",
    "content": "The metrics described above are commonly used to evaluate a regression model. In most real-world scenarios, a data scientist will use an iterative process to repeatedly train and evaluate a model, varying:\n\n- Feature selection and preparation (choosing which features to include in the model, and calculations applied to them to help ensure a better fit).\n- Algorithm selection (We explored linear regression in the previous example, but there are many other regression algorithms)\n- Algorithm parame",
    "summary": "The metrics described above are commonly used to evaluate a regression model. In most real-world scenarios, a data scientist will use an iterative process to repeatedly train and evaluate a model, var...",
    "keywords": [
      "preparation",
      "iterations",
      "results",
      "best",
      "accurately",
      "model",
      "real-world",
      "features",
      "after",
      "regression",
      "data",
      "commonly",
      "algorithms",
      "applied",
      "more",
      "process",
      "them",
      "numeric",
      "example",
      "help"
    ]
  },
  {
    "id": 28,
    "category": "Machine Learning",
    "file": "04-binary-classification.md",
    "heading": "Example - binary classification",
    "content": "To understand how binary classification works, let's look at a simplified example that uses a single feature (***x***) to predict whether the label ***y*** is 1 or 0. In this example, we'll use the blood glucose level of a patient to predict whether or not the patient has diabetes. Here's the data with which we'll train the model:\n\n|![Diagram of a syringe.](../media/blood-glucose.png)|![Diagram of a diabetic and non-diabetic person.](../media/diabetes.png)|\n|---|---|\n|**Blood glucose (x)** | **D",
    "summary": "To understand how binary classification works, let's look at a simplified example that uses a single feature (***x***) to predict whether the label ***y*** is 1 or 0. In this example, we'll use the bl...",
    "keywords": [
      "blood",
      "model",
      "blood-glucose",
      "non-diabetic",
      "simplified",
      "data",
      "person",
      "understand",
      "diagram",
      "diabetic",
      "predict",
      "binary",
      "example",
      "look",
      "level",
      "feature",
      "whether",
      "which",
      "syringe",
      "patient"
    ]
  },
  {
    "id": 29,
    "category": "Machine Learning",
    "file": "04-binary-classification.md",
    "heading": "Training a binary classification model",
    "content": "To train the model, we'll use an algorithm to fit the training data to a function that calculates the *probability* of the class label being *true* (in other words, that the patient has diabetes). Probability is measured as a value between 0.0 and 1.0, such that the *total* probability for *all* possible classes is 1.0. So for example, if the probability of a patient having diabetes is 0.7, then there's a corresponding probability of 0.3 that the patient isn't</u> diabetic.\n\nThere are many algor",
    "summary": "To train the model, we'll use an algorithm to fit the training data to a function that calculates the *probability* of the class label being *true* (in other words, that the patient has diabetes). Pro...",
    "keywords": [
      "diagram",
      "algorithms",
      "point",
      "having",
      "includes",
      "level",
      "values",
      "algorithm",
      "sigmoid",
      "which",
      "mathematically",
      "describes",
      "calculates",
      "total",
      "patient",
      "lies",
      "know",
      "used",
      "many",
      "definitely"
    ]
  },
  {
    "id": 30,
    "category": "Machine Learning",
    "file": "04-binary-classification.md",
    "heading": "Evaluating a binary classification model",
    "content": "As with regression, when training a binary classification model you hold back a random subset of data with which to validate the trained model. Let's assume we held back the following data to validate our diabetes classifier:\n\n|Blood glucose (x) | Diabetic? (y)|\n|---|---|\n|66|0|\n|107|1|\n|112|1|\n|71|0|\n|87|1|\n|89|1|\n\nApplying the logistic function we derived previously to the ***x*** values results in the following plot. \n\n![Diagram of predicted labels on a sigmoid curve.](../media/classification",
    "summary": "As with regression, when training a binary classification model you hold back a random subset of data with which to validate the trained model. Let's assume we held back the following data to validate...",
    "keywords": [
      "function",
      "applying",
      "results",
      "blood",
      "validate",
      "model",
      "diagnosis",
      "classification-predictions",
      "regression",
      "data",
      "classifier",
      "curve",
      "based",
      "diagram",
      "diabetic",
      "previously",
      "evaluating",
      "below",
      "binary",
      "values"
    ]
  },
  {
    "id": 31,
    "category": "Machine Learning",
    "file": "04-binary-classification.md",
    "heading": "Binary classification evaluation metrics",
    "content": "The first step in calculating evaluation metrics for a binary classification model is usually to create a matrix of the number of correct and incorrect predictions for each possible class label:\n\n![Diagram of a confusion matrix.](../media/binary-confusion-matrix.png)\n\nThis visualization is called a *confusion matrix*, and it shows the prediction totals where:\n\n- &#375;=0 and y=0: *True negatives* (TN)\n- &#375;=1 and y=0: *False positives* (FP)\n- &#375;=0 and y=1: *False negatives* (FN)\n- &#375;=",
    "summary": "The first step in calculating evaluation metrics for a binary classification model is usually to create a matrix of the number of correct and incorrect predictions for each possible class label:\n\n![Di...",
    "keywords": [
      "positives",
      "model",
      "correct",
      "color-intensity",
      "step",
      "diagram",
      "true",
      "cell",
      "totals",
      "well",
      "binary",
      "glance",
      "deeply",
      "negatives",
      "bottom-right",
      "confusion",
      "indicate",
      "false",
      "line",
      "predicts"
    ]
  },
  {
    "id": 32,
    "category": "Machine Learning",
    "file": "04-binary-classification.md",
    "heading": "Accuracy",
    "content": "The simplest metric you can calculate from the confusion matrix is *accuracy* - the proportion of predictions that the model got right. Accuracy is calculated as:\n\n***(TN+TP) &#247; (TN+FN+FP+TP)***\n\nIn the case of our diabetes example, the calculation is:\n\n(2+3) &#247; (2+1+0+3)\n\n= 5 &#247; 6\n\n= **0.83**\n\nSo for our validation data, the diabetes classification model produced correct predictions 83% of the time.\n\nAccuracy might initially seem like a good metric to evaluate a model, but consider ",
    "summary": "The simplest metric you can calculate from the confusion matrix is *accuracy* - the proportion of predictions that the model got right. Accuracy is calculated as:\n\n***(TN+TP) &#247; (TN+FN+FP+TP)***...",
    "keywords": [
      "even",
      "real",
      "case",
      "model",
      "correct",
      "features",
      "seem",
      "validation",
      "data",
      "performs",
      "produced",
      "accuracy",
      "evaluating",
      "calculate",
      "like",
      "example",
      "time",
      "right",
      "simplest",
      "differentiate"
    ]
  },
  {
    "id": 33,
    "category": "Machine Learning",
    "file": "04-binary-classification.md",
    "heading": "Recall",
    "content": "*Recall* is a metric that measures the proportion of positive cases that the model identified correctly. In other words, compared to the number of patients who *have* diabetes, how many did the model *predict* to have diabetes?\n\nThe formula for recall is:\n\n***TP &#247; (TP+FN)***\n\nFor our diabetes example:\n\n3 &#247; (3+1)\n\n= 3 &#247; 4\n\n= **0.75**\n\nSo our model correctly identified 75% of patients who have diabetes as having diabetes.",
    "summary": "*Recall* is a metric that measures the proportion of positive cases that the model identified correctly. In other words, compared to the number of patients who *have* diabetes, how many did the model...",
    "keywords": [
      "model",
      "correctly",
      "having",
      "predict",
      "example",
      "formula",
      "proportion",
      "recall",
      "metric",
      "number",
      "measures",
      "words",
      "diabetes",
      "many",
      "cases",
      "positive",
      "identified",
      "other",
      "compared",
      "patients"
    ]
  },
  {
    "id": 34,
    "category": "Machine Learning",
    "file": "04-binary-classification.md",
    "heading": "Precision",
    "content": "*Precision* is a similar metric to recall, but measures the proportion of predicted positive cases where the true label is actually positive. In other words, what proportion of the patients *predicted* by the model to have diabetes actually *have* diabetes?\n\nThe formula for precision is:\n\n***TP &#247; (TP+FP)***\n\nFor our diabetes example:\n\n3 &#247; (3+0)\n\n= 3 &#247; 3\n\n= **1.0**\n\nSo 100% of the patients predicted by our model to have diabetes do in fact have diabetes.",
    "summary": "*Precision* is a similar metric to recall, but measures the proportion of predicted positive cases where the true label is actually positive. In other words, what proportion of the patients *predicted...",
    "keywords": [
      "model",
      "true",
      "example",
      "precision",
      "formula",
      "proportion",
      "recall",
      "similar",
      "actually",
      "metric",
      "predicted",
      "measures",
      "words",
      "diabetes",
      "cases",
      "label",
      "positive",
      "other",
      "what",
      "patients"
    ]
  },
  {
    "id": 35,
    "category": "Machine Learning",
    "file": "04-binary-classification.md",
    "heading": "F1-score",
    "content": "*F1-score* is an overall metric that combines recall and precision. The formula for F1-score is:\n\n***(2 x Precision x Recall) &#247; (Precision + Recall)***\n\nFor our diabetes example:\n\n(2 x 1.0 x 0.75) &#247; (1.0 + 0.75)\n\n= 1.5 &#247; 1.75\n\n**= 0.86**",
    "summary": "*F1-score* is an overall metric that combines recall and precision. The formula for F1-score is:\n\n***(2 x Precision x Recall) &#247; (Precision + Recall)***\n\nFor our diabetes example:\n\n(2 x 1.0 x 0.75...",
    "keywords": [
      "recall",
      "metric",
      "example",
      "f1-score",
      "combines",
      "precision",
      "formula",
      "diabetes",
      "overall"
    ]
  },
  {
    "id": 36,
    "category": "Machine Learning",
    "file": "04-binary-classification.md",
    "heading": "Area Under the Curve (AUC)",
    "content": "Another name for recall is the *true positive rate* (TPR), and there's an equivalent metric called the *false positive rate* (FPR) that is calculated as **FP&#247;(FP+TN)**. We already know that the TPR for our model when using a threshold of 0.5 is 0.75, and we can use the formula for FPR to calculate a value of 0&#247;2 = 0.\n\nOf course, if we were to change the threshold above which the model predicts *true* (**1**), it would affect the number of positive and negative predictions; and therefor",
    "summary": "Another name for recall is the *true positive rate* (TPR), and there's an equivalent metric called the *false positive rate* (FPR) that is calculated as **FP&#247;(FP+TN)**. We already know that the T...",
    "keywords": [
      "equivalent",
      "perfect",
      "guessing",
      "diagram",
      "reasonably",
      "using",
      "calculate",
      "metrics",
      "which",
      "number",
      "across",
      "patient",
      "know",
      "used",
      "called",
      "plot",
      "another",
      "predictions",
      "when",
      "media"
    ]
  },
  {
    "id": 37,
    "category": "Machine Learning",
    "file": "05-multiclass-classification.md",
    "heading": "Example - multiclass classification",
    "content": "Multiclass classification algorithms are used to calculate probability values for multiple class labels, enabling a model to predict the *most probable* class for a given observation.\n\nLet's explore an example in which we have some observations of penguins, in which the flipper length (***x***) of each penguin is recorded. For each observation, the data includes the penguin species (***y***), which is encoded as follows:\n\n- 0: Adelie\n- 1: Gentoo\n- 2: Chinstrap\n\n\n\n|![Diagram of a measuring ruler.",
    "summary": "Multiclass classification algorithms are used to calculate probability values for multiple class labels, enabling a model to predict the *most probable* class for a given observation.\n\nLet's explore a...",
    "keywords": [
      "adelie",
      "measuring",
      "three",
      "model",
      "data",
      "follows",
      "probable",
      "diagram",
      "given",
      "algorithms",
      "recorded",
      "includes",
      "calculate",
      "predict",
      "example",
      "probability",
      "values",
      "explore",
      "penguins",
      "observation"
    ]
  },
  {
    "id": 38,
    "category": "Machine Learning",
    "file": "05-multiclass-classification.md",
    "heading": "Training a multiclass classification model",
    "content": "To train a multiclass classification model, we need to use an algorithm to fit the training data to a function that calculates a probability value for each possible class. There are two kinds of algorithm you can use to do this:\n\n- One-vs-Rest (OvR) algorithms\n- Multinomial algorithms",
    "summary": "To train a multiclass classification model, we need to use an algorithm to fit the training data to a function that calculates a probability value for each possible class. There are two kinds of algor...",
    "keywords": [
      "function",
      "model",
      "data",
      "algorithms",
      "probability",
      "kinds",
      "algorithm",
      "need",
      "one-vs-rest",
      "each",
      "calculates",
      "training",
      "possible",
      "multinomial",
      "class",
      "there",
      "value",
      "classification",
      "multiclass",
      "train"
    ]
  },
  {
    "id": 39,
    "category": "Machine Learning",
    "file": "05-multiclass-classification.md",
    "heading": "One-vs-Rest (OvR) algorithms",
    "content": "One-vs-Rest algorithms train a binary classification function for each class, each calculating the probability that the observation is an example of the target class. Each function calculates the probability of the observation being a specific class compared to *any* other class. For our penguin species classification model, the algorithm would essentially create three binary classification functions:\n\n- ***f<sup>0</sup>(x) = P(y=0 | x)***\n- ***f<sup>1</sup>(x) = P(y=1 | x)***\n- ***f<sup>2</sup>",
    "summary": "One-vs-Rest algorithms train a binary classification function for each class, each calculating the probability that the observation is an example of the target class. Each function calculates the prob...",
    "keywords": [
      "function",
      "three",
      "model",
      "highest",
      "algorithms",
      "produces",
      "using",
      "binary",
      "probability",
      "example",
      "between",
      "output",
      "algorithm",
      "sigmoid",
      "observation",
      "predicts",
      "specific",
      "kind",
      "species",
      "one-vs-rest"
    ]
  },
  {
    "id": 40,
    "category": "Machine Learning",
    "file": "05-multiclass-classification.md",
    "heading": "Multinomial algorithms",
    "content": "As an alternative approach is to use a multinomial algorithm, which creates a single function that returns a multi-valued output. The output is a *vector* (an array of values) that contains the *probability distribution* for all possible classes - with a probability score for each class which when totaled add up to 1.0:\n\n***f(x) =[P(y=0|x), P(y=1|x), P(y=2|x)]***\n\nAn example of this kind of function is a *softmax* function, which could produce an output like the following example:\n\n[0.2, 0.3, 0.",
    "summary": "As an alternative approach is to use a multinomial algorithm, which creates a single function that returns a multi-valued output. The output is a *vector* (an array of values) that contains the *proba...",
    "keywords": [
      "function",
      "classes",
      "score",
      "case",
      "model",
      "totaled",
      "probabilities",
      "features",
      "alternative",
      "highest",
      "probable",
      "given",
      "represent",
      "algorithms",
      "creates",
      "vector",
      "softmax",
      "resulting",
      "produce",
      "approach"
    ]
  },
  {
    "id": 41,
    "category": "Machine Learning",
    "file": "05-multiclass-classification.md",
    "heading": "Evaluating a multiclass classification model",
    "content": "You can evaluate a multiclass classifier by calculating binary classification metrics for each individual class. Alternatively, you can calculate aggregate metrics that take all classes into account.\n\nLet's assume that we've validated our multiclass classifier, and obtained the following results:\n\n|Flipper length (x) | Actual species (y)| Predicted species (&#375;)|\n|---|---|--|\n|165|0|0|\n|171|0|0|\n|205|2|1|\n|195|1|1|\n|183|1|1|\n|221|2|2|\n|214|2|2|\n\nThe confusion matrix for a multiclass classifie",
    "summary": "You can evaluate a multiclass classifier by calculating binary classification metrics for each individual class. Alternatively, you can calculate aggregate metrics that take all classes into account....",
    "keywords": [
      "classes",
      "results",
      "model",
      "f1-score",
      "take",
      "classifier",
      "diagram",
      "follows",
      "true",
      "accuracy",
      "evaluating",
      "using",
      "except",
      "calculate",
      "binary",
      "86x0",
      "validated",
      "confusion",
      "precision",
      "negative"
    ]
  },
  {
    "id": 42,
    "category": "Machine Learning",
    "file": "06-clustering.md",
    "heading": "Example - clustering",
    "content": "For example, suppose a botanist observes a sample of flowers and records the number of leaves and petals on each flower:\n\n![Diagram of some flowers.](../media/flowers.png)\n\nThere are no known *labels* in the dataset, just two *features*. The goal is not to identify the different types (species) of flower; just to group similar flowers together based on the number of leaves and petals.\n\n|Leaves *(x<sub>1</sub>)*| Petals *(x<sub>2</sub>)*|\n|-|-|\n|0|5|\n|0|6|\n|1|3|\n|1|3|\n|1|6|\n|1|8|\n|2|3|\n|2|7|\n|2|8",
    "summary": "For example, suppose a botanist observes a sample of flowers and records the number of leaves and petals on each flower:\n\n![Diagram of some flowers.](../media/flowers.png)\n\nThere are no known *labels*...",
    "keywords": [
      "flower",
      "records",
      "features",
      "leaves",
      "just",
      "based",
      "diagram",
      "media",
      "dataset",
      "example",
      "types",
      "observes",
      "sample",
      "different",
      "similar",
      "group",
      "identify",
      "clustering",
      "species",
      "number"
    ]
  },
  {
    "id": 43,
    "category": "Machine Learning",
    "file": "06-clustering.md",
    "heading": "Training a clustering model",
    "content": "There are multiple algorithms you can use for clustering. One of the most commonly used algorithms is *K-Means* clustering, which consists of the following steps:\n\n1. The feature (***x***) values are vectorized to define *n*-dimensional coordinates (where *n* is the number of features). In the flower example, we have two features: number of leaves (***x<sub>1</sub>***) and number of petals (***x<sub>2</sub>***). So, the feature vector has two coordinates that we can use to conceptually plot the ",
    "summary": "There are multiple algorithms you can use for clustering. One of the most commonly used algorithms is *K-Means* clustering, which consists of the following steps:\n\n1. The feature (***x***) values are...",
    "keywords": [
      "showing",
      "-dimensional",
      "animation",
      "diagram",
      "algorithms",
      "process",
      "point",
      "plotted",
      "values",
      "reallocation",
      "consists",
      "centroid",
      "maximum",
      "which",
      "number",
      "two-dimensional",
      "used",
      "many",
      "plot",
      "decide"
    ]
  },
  {
    "id": 44,
    "category": "Machine Learning",
    "file": "06-clustering.md",
    "heading": "Evaluating a clustering model",
    "content": "Since there's no known label with which to compare the predicted cluster assignments, evaluation of a clustering model is based on how well the resulting clusters are separated from one another.\n\nThere are multiple metrics that you can use to evaluate cluster separation, including:\n\n- **Average distance to cluster center**: How close, on average, each point in the cluster is to the centroid of the cluster.\n- **Average distance to other center**: How close, on average, each point in the cluster i",
    "summary": "Since there's no known label with which to compare the predicted cluster assignments, evaluation of a clustering model is based on how well the resulting clusters are separated from one another.\n\nTher...",
    "keywords": [
      "closer",
      "furthest",
      "cluster",
      "model",
      "average",
      "summarizes",
      "close",
      "based",
      "silhouette",
      "same",
      "evaluating",
      "point",
      "resulting",
      "well",
      "separated",
      "including",
      "center",
      "between",
      "since",
      "compare"
    ]
  },
  {
    "id": 45,
    "category": "Machine Learning",
    "file": "07-deep-learning.md",
    "heading": "Example - Using deep learning for classification",
    "content": "To better understand how a deep neural network model works, let's explore an example in which a neural network is used to define a classification model for penguin species.\n\n![Diagram of a neural network used to classify a penguin species.](../media/deep-classification.png)\n\nThe feature data (***x***) consists of some measurements of a penguin. Specifically, the measurements are:\n\n- The length of the penguin's bill.\n- The depth of the penguin's bill.\n- The length of the penguin's flippers.\n- The",
    "summary": "To better understand how a deep neural network model works, let's explore an example in which a neural network is used to define a classification model for penguin species.\n\n![Diagram of a neural netw...",
    "keywords": [
      "adelie",
      "fully",
      "deep-classification",
      "deep",
      "diagram",
      "process",
      "using",
      "connected",
      "neurons",
      "calculate",
      "depth",
      "values",
      "consists",
      "similar",
      "combining",
      "which",
      "meets",
      "mathematically",
      "species",
      "some"
    ]
  },
  {
    "id": 46,
    "category": "Machine Learning",
    "file": "07-deep-learning.md",
    "heading": "How does a neural network learn?",
    "content": "The weights in a neural network are central to how it calculates predicted values for labels. During the training process, the model *learns* the weights that will result in the most accurate predictions. Let's explore the training process in a little more detail to understand how this learning takes place.\n\n![Diagram of a neural network being trained, evaluated, and optimized.](../media/neural-network-training.png)\n\n1. The training and validation datasets are defined, and the training features ",
    "summary": "The weights in a neural network are central to how it calculates predicted values for labels. During the training process, the model *learns* the weights that will result in the most accurate predicti...",
    "keywords": [
      "changes",
      "containing",
      "accurately",
      "entire",
      "step",
      "minimize",
      "diagram",
      "process",
      "neural-network-training",
      "neurons",
      "approach",
      "values",
      "detail",
      "initially",
      "weights",
      "aggregate",
      "returned",
      "which",
      "apply",
      "influence"
    ]
  }
]