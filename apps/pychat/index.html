<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PyChat - Local AI Code Runner</title>
    <link rel="stylesheet" href="styles.css">
    <!-- Load PyScript -->
    <link rel="stylesheet" href="https://pyscript.net/releases/2024.1.1/core.css">
    <script type="module" src="https://pyscript.net/releases/2024.1.1/core.js"></script>
    <!-- PyScript Config -->
    <script type="py-config">
        packages = []
    </script>
    <!-- Load WebLLM (ES Module shim for browser) -->
    <script type="module">
        import * as webllm from "https://esm.run/@mlc-ai/web-llm";
        window.webllm = webllm;
    </script>
</head>

<body>
    <div class="app-container">
        <header>
            <h1>PyChat</h1>
            <div id="status-indicator" class="status-badge">Initializing...</div>
        </header>

        <main>
            <section class="editor-section">
                <div class="section-header">
                    <div>
                        <h2>Code Editor</h2>
                        <span class="hint">Edit your Python code here</span>
                    </div>
                    <div class="file-controls">
                        <input type="text" id="filename-input" placeholder="script.py" value="script.py">
                        <button id="save-btn">Save File</button>
                        <button id="new-btn">New File</button>
                        <button id="run-btn">Run</button>
                        <select id="file-list">
                            <option value="">-- Select File --</option>
                        </select>
                    </div>
                </div>
                <textarea id="code-editor" spellcheck="false">import openai
import asyncio

# Define an async function to use await
async def chat_with_ai():
    # Initialize messages
    messages = [
        {"role": "system", "content": "You are a helpful AI assistant."},
        {"role": "user", "content": "Hello! Can you write a Python function to calculate the factorial of a number?"}
    ]
    
    print("Sending request to model...")
    
    # Call the model (requires await)
    response = await openai.ChatCompletion.create(
        model="Llama-3.2-1B-Instruct-q4f16_1-MLC",
        messages=messages
    )
    
    # Print the response
    print("\nResponse:")
    print(response.choices[0].message.content)

# Run the async function
asyncio.ensure_future(chat_with_ai())</textarea>
            </section>

            <section class="terminal-section">
                <div class="section-header">
                    <h2>Output</h2>
                    <span class="hint">Script execution output appears here</span>
                </div>
                <div id="output-display"></div>
            </section>
        </main>
    </div>
    <script src="script.js" type="module"></script>
</body>

</html>